
\chapter{Introduction}

% What makes this topic so important?
Emotion recognition through the observation of facial expression is a current trend \citep{Chen:2020:EmotionAI}  \citep{Handrich:2020:SimultaneousPredVA} in Artificial Intelligence. Even though big strides are still to be made in this research area, it already finds its way into concrete business applications. \citet{Chen:2020:EmotionAI} claim that emotion recognition is already being deployed in a variety of different scenarios, such as classrooms and courtrooms. They highlight the adoption of emotion recognition in AI-assisted hiring software, especially in the US and South Korea, where new applicants have to interview online with an algorithm. Video interviews are then analyzed with emotion recognition in order to figure out a candidate's employability score.
\newline\newline
These applications of technological advances in emotion recognition show that this technology has a big optimization and innovation potential. This is why the Hamburg-based software and consulting firm PPI AG regards emotion recognition as a technology that can play a very important role for its clients in the banking and insurance industry. The cooperation with PPI AG for this Master's thesis brings in another interesting aspect about the viability of technological advances in the field of emotion recognition for a possible application in the wild. An initial analysis of the field (in cooperation with PPI AG) determined that video call consultations between customers as the highest-value application scenario for emotion recognition, where it could help assist consultants and customers.
\newline\newline
PPI AG, in its commitment to continuously offer innovative solutions to their clients, is looking for new ways to harness technological advances such as emotion recognition in order to apply them in real business scenarios. In that vein, PPI AG aims to better serve their customers, create profitable business solutions and to differentiate themselves from competitors. A basis of this builds the scientific examination of the viability of emotion recognition in the wild. Given that the field of emotion recognition is still relatively new, there are shortcomings in terms of the research available.
\newline\newline
The current gaps in the research within this field are the following:\newline
\begin{itemize}
    \item As supported by \citet{Salah:2018:VideoBasedER} emotions are inherently cultural and personal, making the task of universally interpreting them very difficult. Even if emotions were universal, there is still the conflict of representing emotions for machine learning systems. On the one hand, these representations should carry higher information, but should on the other hand also be easily interpretable by humans.
    \item Another problem with current research is that most research is done in laboratories, under controlled and predictable conditions (e.g., a perfectly-illuminated face of a person).
    \item There is a significant lack of knowledge about fine-tuning Deep Convolution Neural Networks (DCNN). While \citet{Kossaifi:2017:AFEW-VADatabase} found that DCNNs performed worst under all their examined approaches, \citet{Handrich:2020:SimultaneousPredVA}, on the other hand, are showcasing results in favor of FT-DCNNs.
    \item It is unclear which modules and frameworks work specifically for recognizing emotions with in-the-wild data.
    \item The lack of focus on business opportunities with emotion recognition can also be seen as a research gap, as more research is needed on how to utilize emotions for more commercial purposes.
\end{itemize}

While it is possible to recognize emotions from various input signals \citep{Akcay:2020:SpeechEmotionRecognition(SER)}, such as facial expressions, speech patterns, and keystrokes, this prototype will be focusing primarily on the recognition of emotions from facial expressions. This simplifies the study, and allows for an easier understanding of the components and modules involved in emotion recognition. Furthermore, it will allow for a better comparison of the results achieved. 
\newline\newline
The main objective of this Master's thesis is to implement a prototype that is able to visually recognize human emotions in the wild. In order to proof that, the outcomes of the implemented prototype application will be compared objectively to state-of-the-art results in current literature.
\newline\newline
Additionally, implemented design choices will be examined separately on whether they contribute positively towards the overall performance of the trained neural network (i.e. ablation study). Among others, different fine-tuning approaches will be compared; most notably Multi-Phased Fine-Tuning (Multi-Phased FT). Instead of training the whole pre-trained network from the beginning (here denoted as Single-Phased Fine-Tuning), the Multi-Phased FT starts off with training only a few layers and adds to them step-wise more layers.
\newline\newline
Another area of special scientific interest are facial landmarks and its ensuing performance changes for emotion recognition. Detected landmarks will be applied in various ways, ranging from a fully-visible overlay to a separate mask that is fed as a fourth image channel into the neural network.
\newline\newline
Moreover, the goal of this prototype is to act as a demonstration tool to illustrate commercial benefits of utilizing emotion recognition, especially during real-time video calls. For this, the prototype will prove its real-time viability by processing video input from a webcam. For the assessment of commercial benefit, a mechanism will be created to map recognized emotions to a level of interest.
\newline\newline
Hereinafter a short introduction to the chapters in this thesis is given:\newline
The \textbf{Methodolgy} chapter presents the proposed approach in concrete and palpable steps -- from the image input to its output. At the core of the approach is the neural network, which will be explained in detail in the \textbf{Implementation} chapter. The neural network will be trained on the Acted Facial Expressions in the wild - Valence Arousal (AFEW-VA) dataset containing in-the-wild video clips, mainly from talk shows and movies.
\newline\newline
In the \textbf{Results and Analysis} chapter, achieved outcomes will be discussed and compared to current state-of-the-art results. This will supplement the gaps in existing literature by providing further insights into the process of fine-tuning DCNNs when handling in-the-wild data. As an extension of this, in the \textbf{Ablation Study} section, a profound analysis is done for the most important modules, in order to illuminate the contributions for each module, separately. The insights obtained through this analysis will contribute towards expanding the knowledge about the positive impact of single modules/frameworks on the performance of emotion recognition with in-the-wild data.
\newline\newline
In the \textbf{Application} chapter, the achieved results will be implemented in an application prototype that can demonstrate real-time viability of such an approach. This will create scientific evidence that will support the maturity of emotion recognition for specific business application scenarios.\newline
Moreover, a user experiment will be conducted that compares the predicted interest based on emotions recognized from facial expressions with the stated level of interest by participants. In this way, conclusions can be drawn about a suspected correlation between emotion recognition and human interest. This will supplement research gaps on the utilization of emotion information for the identification of human interest. 
\newline\newline
% What will my contribution to the scientific community be?
This study's overall contribution to the scientific community can be summarized by the following three points:
\begin{itemize}
    \item Performance of Multi-Phase Fine-Tuning vs. Single-Phase Fine-Tuning in the field of emotion recognition in the wild
    \item Comparison of different ways of dealing with facial landmarks in the field of emotion recognition
    \item Practical insights gained through an experiment on identifying interest by observing people's facial expressions
\end{itemize}