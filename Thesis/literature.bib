
@inproceedings{Gupta:2007:Two-StreamER,
author = {Gupta, Purnima and Rajput, Nitendra},
year = {2007},
month = {01},
pages = {2241-2244},
booktitle = {Two-stream emotion recognition for call center monitoring},
title = {Two-stream emotion recognition for call center monitoring}
}

@inproceedings{Ayadi:2010:SurveyOnSER,
author = {El Ayadi, Moataz and S. Kamel, Mohamed and Karray, Fakhri},
year = {2010},
month = {09},
pages = {572-587},
booktitle = {Pattern Recognition},
title = {Survey on speech emotion recognition: Features, classification schemes, and databases}
}

@ARTICLE{Chen:2018:3DConvRecurrentNN,
  author={M. {Chen} and X. {He} and J. {Yang} and H. {Zhang}},
  journal={IEEE Signal Processing Letters}, 
  title={3-D Convolutional Recurrent Neural Networks With Attention Model for Speech Emotion Recognition}, 
  year={2018},
  volume={25},
  number={10},
  pages={1440-1444},}

@misc{Sharma:2018:RealTimeFacialExpression,
  author = {Sharma, Gaurav},
  title = {Real Time Facial Expression Recognition},
  year = {2018},
  url = {https://medium.com/datadriveninvestor/real-time-facial-expression-recognition-f860dacfeb6a},
  urldate = {2020-05-25}
}

@ARTICLE{Yeasin:2006:MeasurmentOfInterestFromVideo,     
    author={M. {Yeasin} and B. {Bullot} and R. {Sharma}}, journal={IEEE Transactions on Multimedia}, title={Recognition of facial expressions and measurement of levels of interest from video},   year={2006},  volume={8},  number={3},  pages={500-508},
}

@article{Zhang:2016:MTCCN,
   title={Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks},
   volume={23},
   ISSN={1558-2361},
   url={http://dx.doi.org/10.1109/LSP.2016.2603342},
   DOI={10.1109/lsp.2016.2603342},
   number={10},
   journal={IEEE Signal Processing Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
   year={2016},
   month={Oct},
   pages={1499–1503}
}

@Article{Verma:2017:3D-VAD,
author={Verma, Gyanendra K.
and Tiwary, Uma Shanker},
title={Affect representation and recognition in 3D continuous valence--arousal--dominance space},
journal={Multimedia Tools and Applications},
year={2017},
month={Jan},
day={01},
volume={76},
number={2},
pages={2159-2183},
issn={1573-7721},
doi={10.1007/s11042-015-3119-y},
url={https://doi.org/10.1007/s11042-015-3119-y}
}

@misc{Brownlee:2019:VggFace2HowToFaceRec,
  author = {Brownlee, Jason},
  title = {How to Perform Face Recognition With VGGFace2 in Keras},
  year = {2019},
  url = {https://machinelearningmastery.com/how-to-perform-face-recognition-with-vggface2-convolutional-neural-network-in-keras/},
  urldate = {2020-06-01}
}

@article{Kossaifi:2017:AFEW-VADatabase,
    title = "AFEW-VA database for valence and arousal estimation in-the-wild",
    journal = "Image and Vision Computing",
    volume = "65",
    pages = "23 - 36",
    year = "2017",
    note = "Multimodal Sentiment Analysis and Mining in the Wild Image and Vision Computing",
    issn = "0262-8856",
    doi = "https://doi.org/10.1016/j.imavis.2017.02.001",
    url = "http://www.sciencedirect.com/science/article/pii/S0262885617300379",
    author = "Jean Kossaifi and Georgios Tzimiropoulos and Sinisa Todorovic and Maja Pantic",
}

@article{Dhall:2012:AFEW,
 author = {Dhall, Abhinav and Goecke, Roland and Lucey, Simon and Gedeon, Tom},
 title = {Collecting Large, Richly Annotated Facial-Expression Databases from Movies},
 journal = {IEEE MultiMedia},
 issue_date = {July 2012},
 volume = {19},
 number = {3},
 month = jul,
 year = {2012},
 pages = {34--41},
}
  

@INPROCEEDINGS{Cao:2018:VGGFace2, 
    author={Q. {Cao} and L. {Shen} and W. {Xie} and O. M. {Parkhi} and A. {Zisserman}},
    booktitle={2018 13th IEEE International Conference on Automatic Face   Gesture Recognition (FG 2018)},
    title={VGGFace2: A Dataset for Recognising Faces across Pose and Age},
    year={2018},
    volume={},
    number={},
    pages={67-74},}
  
    
@INPROCEEDINGS{Hupont:2010:FacialEmotionsIn2DAffectiveSpace,
    author={I. {Hupont} and E. {Cerezo} and S. {Baldassarri}},
    booktitle={2010 IEEE International Conference on Systems, Man and Cybernetics},
    title={Sensing facial emotions in a continuous 2D affective space},
    year={2010},
    volume={},
    number={},
    pages={2045-2051},}

@book{Ries:2011:TheLeanStartUp,
  title={The Lean Startup: How Today's Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses},
  author={Ries, E.},
  isbn={9780307887894},
  lccn={2011012100},
  series={The Lean Startup: How Today's Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses},
  url={https://books.google.de/books?id=r9x-OXdzpPcC},
  year={2011},
  publisher={Crown Business}
}

@Article{Payne:2008:ValueCo-Creation,
    author={Payne, Adrian F. and Storbacka, Kaj and Frow, Pennie},
    title={Managing the co-creation of value},
    journal={Journal of the Academy of Marketing Science},
    year={2008},
    month={Mar},
    day={01},
    volume={36},
    number={1},
    pages={83-96},
    issn={1552-7824},
    doi={10.1007/s11747-007-0070-0},
    url={https://doi.org/10.1007/s11747-007-0070-0}
}

@INPROCEEDINGS{Lenarduzzi:2016:MVP,
    author={V. {Lenarduzzi} and D. {Taibi}},
    booktitle={2016 42th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
    title={MVP Explained: A Systematic Mapping Study on the Definitions of Minimal Viable Product},
    year={2016},
    volume={},
    number={},
    pages={112-119}
}

@INPROCEEDINGS{Theagarajan:2018:DeepDriver,
    author={R. {Theagarajan} and B. {Bhanu} and A. {Cruz}},
    booktitle={2018 24th International Conference on Pattern Recognition (ICPR)},   title={DeepDriver: Automated System For measuring Valence and Arousal in Car Driver Videos},
    year={2018},
    volume={},
    number={},
    pages={2546-2551},}
    
@article{Handrich:2020:SimultaneousPredVA,
    title = "Simultaneous Prediction of Valence/Arousal and Emotions on AffectNet, Aff-Wild and AFEW-VA",
    journal = "Procedia Computer Science",
    volume = "170",
    pages = "634 - 641",
    year = "2020",
    note = "The 11th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 3rd International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops",
    issn = "1877-0509",
    doi = "https://doi.org/10.1016/j.procs.2020.03.134",
    url = "http://www.sciencedirect.com/science/article/pii/S1877050920305895",
    author = "Sebastian Handrich and Laslo Dinges and Ayoub Al-Hamadi and Philipp Werner and Zaher Al Aghbari",
    keywords = "Affective State, Valence, Arousal"
}

@inproceedings{Yan:2016:MultiClueFusion,
author = {Yan, Jingwei and Zheng, Wenming and Cui, Zhen and Tang, Chuangao and Zhang, Tong and Zong, Yuan and Sun, Ning},
title = {Multi-Clue Fusion for Emotion Recognition in the Wild},
year = {2016},
isbn = {9781450345569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993148.2997630},
doi = {10.1145/2993148.2997630},
booktitle = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
pages = {458–463},
numpages = {6},
keywords = {emotion recognition in the wild, convolutional neural network (CNN), AFEW, recurrent neural network (RNN), multi-clue},
location = {Tokyo, Japan},
series = {ICMI ’16}
}
  
@misc{2020:PearsonCorrelation,
  author = {n.d.},
  title = {Pearson’s Correlation Coefficient},
  year = {n.d.},
  url = {https://www.statisticssolutions.com/pearsons-correlation-coefficient/},
  urldate = {2020-07-13}
}

@misc{2020:RMSE,
  author = {n.d.},
  title = {What is Root Mean Square Error (RMSE)?},
  year = {n.d.},
  url = {https://www.statisticshowto.com/probability-and-statistics/regression-analysis/rmse-root-mean-square-error},
  urldate = {2020-07-13}
}

@Article{Ren:2012:ERforCustomerSatisfaction,
author={Ren, Fuji
and Quan, Changqin},
title={Linguistic-based emotion analysis and recognition for measuring consumer satisfaction: an application of affective computing},
journal={Information Technology and Management},
year={2012},
month={Dec},
day={01},
volume={13},
number={4},
pages={321-332},
issn={1573-7667},
doi={10.1007/s10799-012-0138-5},
url={https://doi.org/10.1007/s10799-012-0138-5}
}
    
@INPROCEEDINGS{Kamaruddin:2016:MeasuringCustomerSatisfaction,  author={N. {Kamaruddin} and A. W. A. {Rahman} and A. N. R. {Shah}},  booktitle={2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M)},  title={Measuring Customer Satisfaction through Speech Using Valence-Arousal Approach},   year={2016},  volume={},  number={},  pages={298-303},}


@mastersthesis{Esser:2018:LandmarkDetection,
  author       = {E{\ss}er, Jan}, 
  title        = {Verbesserung der Präzision der Landmark-Detektion bei Gesichtern mittels Machine Learning},
  school       = {RWTH Aachen University},
  year         = 2018,
  address      = {Germany}}
  
 
@INPROCEEDINGS{Dong:2012:UnderstandHumanImplicitIntention,  author={ {Suh-Yeon Dong} and  {Soo-Young Lee}},  booktitle={The 2012 International Joint Conference on Neural Networks (IJCNN)},  title={Understanding human implicit intention based on frontal electroencephalography (EEG)},   year={2012},  volume={},  number={},  pages={1-5},}


@ARTICLE{Hossain:2019:AudioVisualER,  author={M. S. {Hossain} and G. {Muhammad}},  journal={IEEE Wireless Communications},   title={An Audio-Visual Emotion Recognition System Using Deep Learning Fusion for a Cognitive Wireless Framework},   year={2019},  volume={26},  number={3},  pages={62-68},}

@ARTICLE{Xing:2019:EEGAudioVisual,  author={B. {Xing} and H. {Zhang} and K. {Zhang} and L. {Zhang} and X. {Wu} and X. {Shi} and S. {Yu} and S. {Zhang}},  journal={IEEE Access},   title={Exploiting EEG Signals and Audiovisual Feature Fusion for Video Emotion Recognition},   year={2019},  volume={7},  number={},  pages={59844-59861},}

@article{Akcay:2020:SpeechEmotionRecognition(SER),
title = "Speech emotion recognition: Emotional models, databases, features, preprocessing methods, supporting modalities, and classifiers",
journal = "Speech Communication",
volume = "116",
pages = "56 - 76",
year = "2020",
issn = "0167-6393",
doi = "https://doi.org/10.1016/j.specom.2019.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S0167639319302262",
author = "Mehmet Berkehan Akçay and Kaya Oğuz",
keywords = "Speech emotion recognition, Survey, Speech features, Classification, Speech databases",
}

@misc{Noldus:2020:Facereader,
  author = {Noldus},
  title = {Emotion Analysis FaceReader},
  year = {2020},
  url = {https://www.noldus.com/facereader},
  urldate = {2020-07-23}
}

@misc{Poirier:2016:AdsFacialExpression,
  author = {Amelie Beriault Poirier},
  title = {Facial Expressions and Survey to Measure the Effectiveness of 10 Ads},
  year = {2016},
  url = {http://www.imarklab.com/en/2016/06/facial-expressions-survey-ads/},
  urldate = {2020-07-27}
}

@inproceedings{Pittaras:2017:FineTuningStrategiesComparison,
    author = {Pittaras, Nikiforos and Markatopoulou, Fotini and Mezaris, Vasileios and Patras, Ioannis},
    year = {2017},
    month = {01},
    pages = {102-114},
    booktitle = {MultiMedia Modeling},
    title = {Comparison of Fine-Tuning and Extension Strategies for Deep Convolutional Neural Networks},
    volume = {10132}
}

@inproceedings{Kazemi:2014:ShapePredictor,
  title={One Millisecond Face Alignment with an Ensemble of Regression Trees},
  author={Kazemi, Vahid and Sullivan, Josephine},
  booktitle={CVPR},
  year={2014}
}

@ARTICLE{Gao:2010:ActiveAppearanceModels,  
    author={X. {Gao} and Y. {Su} and X. {Li} and D. {Tao}},  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},   
    title={A Review of Active Appearance Models},   
    year={2010},  
    volume={40},  
    number={2},  
    pages={145-158},}

@misc{Datahacker:2020:DlibFacialLandmarks,
  author = {Datahacker},
  title = {How to detect facial landmarks using DLIB and OpenCV},
  year = {2020},
  url = {http://datahacker.rs/009-how-to-detect-facial-landmarks-using-dlib-and-opencv/},
  urldate = {2020-09-29}
}

@misc{Anzalone:2018:DlibShapePredictor,
  author = {Anzalone, Luca},
  title = {Training alternative Dlib Shape Predictor models using Python},
  year = {2018},
  url = {https://medium.com/datadriveninvestor/training-alternative-dlib-shape-predictor-models-using-python-d1d8f8bd9f5c},
  urldate = {2020-09-29}
}

@misc{Jung:2020:Imgaug,
  author = {Jung, Alexander},
  title = {Imgaug},
  year = {2020},
  url = {https://imgaug.readthedocs.io/en/latest/},
  urldate = {2020-09-29}
}

@misc{Roehrich:2020:TrainValidateTest,
  author = {Röhrich, Günter},
  title = {Train, Validate, Test — Why Splitting Datasets is Essential for Every Machine Learning Algorithm},
  year = {n.d.},
  url = {https://towardsdatascience.com/train-test-split-c3eed34f763b},
  urldate = {2020-10-01}
}

@book{Chollet:2017:DeepLearningPython,
  added-at = {2018-08-01T08:16:18.000+0200},
  author = {Chollet, François},
  biburl = {https://www.bibsonomy.org/bibtex/231f94815ebbd65d3a31e4a69e818573e/jaeschke},
  interhash = {cfbfd3f93853a469e5e6978f61a74a0a},
  intrahash = {31f94815ebbd65d3a31e4a69e818573e},
  isbn = {9781617294433},
  keywords = {ai deeplearning ml},
  month = nov,
  publisher = {Manning},
  timestamp = {2018-08-01T08:16:18.000+0200},
  title = {Deep Learning with Python },
  year = 2017
}

@book{Goodfellow:2016:DeepLearning,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{Dwivedi:2019:ResNetInKeras,
  author = {Dwivedi, Priya},
  title = {Understanding and Coding a ResNet in Keras},
  year = {2019},
  url = {https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33\#:~:text=The\%20ResNet\%2D50\%20model\%20consists,over\%2023\%20million\%20trainable\%20parameters.},
  urldate = {2020-10-08}
}

@mastersthesis{Sheikholeslami:2019:AblationProgrammingML,
  author       = {Sheikholeslami, Sina}, 
  title        = {Ablation Programming for
Machine Learning},
  school       = {KTH, School of Electrical Engineering and Computer Science (EECS)},
  year         = 2019,
  address      = {Germany}}
%http://www.diva-portal.org/smash/get/diva2:1349978/FULLTEXT01.pdf
  
@misc{Fadelli:2018:AblationInANN,
    author = {Fadelli, Ingrid},
    title = {Using ablation to examine the structure of artificial neural networks},
    year = {2018},
    url = {https://techxplore.com/news/2018-12-ablation-artificial-neural-networks.html},
    urldate = {2020-10-08}
}

@misc{Yuanzhi:2019:RegularizationInitialLargeLearningRate,
author = {Li, Yuanzhi and Wei, Colin and Ma, Tengyu},
year = {2019},
month = {07},
pages = {},
title = {Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks}
}
  
@article{Keskar:2016:LargeBatchTrainingGeneralization,
  author    = {Nitish Shirish Keskar and
               Dheevatsa Mudigere and
               Jorge Nocedal and
               Mikhail Smelyanskiy and
               Ping Tak Peter Tang},
  title     = {On Large-Batch Training for Deep Learning: Generalization Gap and
               Sharp Minima},
  journal   = {CoRR},
  volume    = {abs/1609.04836},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.04836},
  archivePrefix = {arXiv},
  eprint    = {1609.04836},
  timestamp = {Mon, 13 Aug 2018 16:46:48 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KeskarMNST16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout
w3c valid html last updated on 

@inbook{Salah:2018:VideoBasedER,
author = {Salah, Albert and Kaya, Heysem and Gürpınar, Furkan},
year = {2018},
month = {12},
pages = {369–386},
publisher = {ResearchGate},
booktitle = {Multimodal Behavior Analysis in the Wild},
title = {Video-Based Emotion Recognition in the Wild},
doi = {10.1016/B978-0-12-814601-9.00031-6}
}

@INPROCEEDINGS{Gunes:2011:EmotionRepresentationContinuous,  
    author={H. {Gunes} and B. {Schuller} and M. {Pantic} and R. {Cowie}},  
    booktitle={Face and Gesture 2011},   
    title={Emotion representation, analysis and synthesis in continuous space: A survey},   
    year={2011},  
    volume={},  
    number={},  
    pages={827-834},}

@article{Barrett:2019:EmotionalFromFacialMovements,
author = {Lisa Feldman Barrett and Ralph Adolphs and Stacy Marsella and Aleix M. Martinez and Seth D. Pollak},
title ={Emotional Expressions Reconsidered: Challenges to Inferring Emotion From Human Facial Movements},
journal = {Psychological Science in the Public Interest},
volume = {20},
number = {1},
pages = {1-68},
year = {2019},
doi = {10.1177/1529100619832930},
note ={PMID: 31313636},
URL = {https://doi.org/10.1177/1529100619832930},
eprint = {https://doi.org/10.1177/1529100619832930}
}

@inbook{Baenziger:2014:MeasuringERAbility,
author="Baenziger, Tanja",
title="Measuring Emotion Recognition Ability",
bookTitle="Encyclopedia of Quality of Life and Well-Being Research",
year="2014",
publisher="Springer Netherlands",
address="Dordrecht",
pages="3934--3941",
isbn="978-94-007-0753-5",
}

@article{Ekman:2002:FACS,
author="EKMAN, P.",
title="Facial Action Coding System (FACS)",
journal="A Human Face",
ISSN="",
publisher="",
year="2002",
month="",
volume="",
number="",
pages="",
URL="https://ci.nii.ac.jp/naid/10025007347/en/",
DOI="",
}


@misc{Sarhan:2020:MultiPhaseFineTuning,
author = {Sarhan, Noha and Lauri, Mikko and Frintrop, Simone},
title = {Multi-Phase Fine-Tuning: A New Fine-Tuning Approach for Sign
Language Recognition},
year = {2020}
}

@misc{Chen:2020:EmotionAI,
author = {Chen, Angela and Hao, Karen},
title = {Emotion AI researchers say overblown claims give their work a bad name},
year = {2020}
}

@misc{Pedro:2018:TransferLearning,
    author = {Marcelino, Pedro},
    title = {Transfer learning from pre-trained models},
    year = {2018},
    url = {https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751},
    urldate = {2020-01-17}
}

@article{Kollias:2019:AffWild, 
    title={Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond}, 
    author={Kollias, Dimitrios and Tzirakis, Panagiotis and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Schuller, Bj{\"o}rn and Kotsia, Irene and Zafeiriou, Stefanos}, 
    journal={International Journal of Computer Vision}, 
    pages={1--23}, 
    year={2019}, 
    publisher={Springer} }
