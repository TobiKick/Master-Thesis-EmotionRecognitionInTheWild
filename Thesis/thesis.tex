\documentclass[11pt,a4paper]{scrbook}
\usepackage{geometry}	
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[pdftex]{graphicx}
\usepackage[ngerman, english]{babel} % the language specified at the end of the list will be used !!
\usepackage{colortbl}	
\usepackage{soul}
% For APA referencing style
%\usepackage[natbibapa]{apacite}
%\bibliographystyle{apacite}

\usepackage[numbers]{natbib}
\bibliographystyle{plainnat}

\usepackage{textcomp}
\usepackage{booktabs} % for latext table
\usepackage{subfig}

\renewcommand{\familydefault}{\sfdefault}
\usepackage{xcolor}
\definecolor{uhhred}{cmyk}{0,100,100,0}
\usepackage{float}
\usepackage[ddmmyyyy]{datetime}
\usepackage{comment}
\usepackage[acronym,nomain]{glossaries}
\usepackage{enumitem}
\usepackage{pdflscape}
\usepackage{url}  % to break the line in long links in bibliography

% for the legend of the conditions
\usepackage{array,tabularx}
\newenvironment{conditions*}
  {\par\vspace{\abovedisplayskip}\noindent
   \tabularx{\columnwidth}{>{$}l<{$} @{\ : } >{\raggedright\arraybackslash}X}}
  {\endtabularx\par\vspace{\belowdisplayskip}}
  
  
  

% Generate the glossary
\makeglossaries

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newacronym{ML}{ML}{Machine Learning}
\newacronym{EEG}{EEG}{Electroencephalography}
\newacronym{ADR}{ADR}{Action Design Research}
\newacronym{MTCNN}{MTCNN}{Multi-Task Cascaded Convolutional Neural Network}
\newacronym{AAM}{AAM}{Active Appearance Model}
\newacronym{FT}{FT}{Fine-Tuning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\frontmatter  % The \frontmatter declaration makes the pages numbered in lowercase roman
\newgeometry{centering,left=2cm,right=2cm,top=2cm,bottom=2cm}
\begin{titlepage}
\includegraphics[scale=0.3]{UHH-Logo_2010_Farbe_CMYK.pdf}
\vspace*{2.0cm}
\Large
\begin{center}
{\color{uhhred}\textbf{\so{MASTER THESIS}}}
\vspace*{1.0cm}\\
{\textbf{at the University of Hamburg in the Department of Computer Science in the master's programme IT Management and Consulting}}
\vspace*{2.0cm}\\
{\LARGE \textbf{Title:}}
\vspace*{0.4cm}\\
{\LARGE Visual Emotion Recognition in The Wild}
%{\LARGE Visual Emotion Recognition in The Wild: Prediction of Valence/Arousal and Assessment of Application scenarios}
%{\LARGE Identifying customer intentions in real-time video consultations through emotion recognition: Analysis of viability and value co-creation by implementation of a prototype}
\vspace*{1.5cm}\\
presented by
\vspace*{0.4cm}\\
Tobias Kick
\end{center}
\vspace*{2.0cm}

\noindent
MIN-Faculty \vspace*{0.25cm} \\
Department of Computer Science\vspace*{0.25cm} \\
Program: IT Management and Consulting\vspace*{0.25cm} \\
Research group: Computer Vision\vspace*{0.25cm} \\
Matriculation number: 7213712 \vspace*{0.5cm} \\
%Submission date: 15/12/2020 \vspace*{0.5cm} \\  
Supervisor: Noha Sarhan \vspace*{0.25cm} \\
First assessor: Prof. Dr. Simone Frintrop \vspace*{0.25cm} \\
Second assessor: Dr. Mikko Lauri

\end{titlepage}

\restoregeometry

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Abstract}
The goal of this Master's thesis is to explore the possibilities of the current state-of-the-art in emotion recognition in the wild. A prototype was implemented that aims to possibly break records set in this field. In addition, findings were applied to the business use-case of online video-call consultations.
\newline\newline
For this, the Acted Facial Expressions in The Wild - Valence Arousal (AFEW-VA) dataset \citep{Kossaifi:2017:AFEW-VADatabase}, consisting of talk-show and movie clips, was utilized. This work confirmed that emotions can be recognized reliably from in-the-wild data. After optimizing the model's hyper-parameters, the obtained results could indeed outperform all baseline methods, as well as one out of three selected state-of-the-art scientific papers. The two other state-of-the-art papers achieved better results, but were training their model on more data coming from two different datasets.
\newline\newline
The best results in this work were obtained through the utilization of a pre-trained Convolutional Neural Network (CNN), called VGGFace, in combination with a Recurrent Neural Network (RNN). This combination makes it possible to use the CNN for the extraction of facial features and leverage the RNN architecture for capturing tempo-spatial information in frames of a video-clip. Moreover, the thesis will shed a light on the most important design choices, such as the inclusion of an external face detection and landmark detection module. All the outcomes of this work resulted in a prototype application that can recognize emotions in real-time from a computer's webcam stream.
\newline\newline
An important practical aspect of this thesis is the application of results in the real-life business use case of video consultations. Therefore, a mapping mechanism was devised from emotional valence to interest, and an user experiment was set up in order to validate this approach. It could be proven that there exists a statistically significant correlation of 0.35 between a subject's indicated interest and the identified interest based on emotion recognition. This leads to the conclusion that this Master's thesis could confirm that it is possible to recognized emotions based on facial features, and to map them effectively to a measure of human interest.
\newline\newline
A recommended next step to this thesis's work is the utilization of more training data from one or more additional databases in order to increase the model's generalization capability.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents% Inhaltsverzeichnis
\listoffigures% Abbildungsverzeichnis
\listoftables% Tabellenverzeichnis

\glsaddall
\printglossary

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\include{Thesis/include/1_introduction}
\include{Thesis/include/2_related_work}
\include{Thesis/include/3_methodology}
\include{Thesis/include/4_implementation}
\include{Thesis/include/5_analysis}
\include{Thesis/include/6_application}
\include{Thesis/include/7_conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\backmatter

%Zum Einbinden des BibTeX Files:
\bibliography{literature.bib}{\nocite{*}}


\newpage
\thispagestyle{empty}
\vspace*{\fill}
\pagestyle{empty}

{\normalsize
\begin{center}\textbf{Sworn declaration}\end{center}
I hereby affirm in lieu of oath that I have independently written the present thesis in the Master's program IT Management and Consulting and that I have not used any tools other than those indicated -- especially no Internet sources not mentioned in the list of sources. All passages that have been taken literally or analogously from publications are marked as such. I further affirm that I have not previously submitted the paper in any other examination procedure and that the submitted written version corresponds to the version on the electronic storage medium.\gls{MTCNN}
\vspace*{1cm}\\
Hamburg, \today
\hspace*{\fill}\begin{tabular}{@{}l@{}}\hline
\makebox[5cm]{Tobias Kick}
\end{tabular}
\vspace*{3cm}

%TODO Dies ist optional, ggf. l√∂schen!
\begin{center}\textbf{Publication}\end{center}
I agree to the placement of the work in the library of the Department of Computer Science.
\vspace*{1cm}\\
Hamburg, \today
\hspace*{\fill}\begin{tabular}{@{}l@{}}\hline
\makebox[5cm]{Tobias Kick}
\end{tabular}
}
\vspace*{\fill}

\end{document}