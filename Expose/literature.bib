
@article{Sein:2011:ActionDesignResearch,
author = {Sein, Maung and Henfridsson, Ola and Purao, Sandeep and Rossi, Matti and Lindgren, Rikard},
year = {2011},
month = {03},
pages = {37-56},
title = {Action Design Research},
volume = {35},
journal = {MIS Quarterly},
doi = {10.2307/23043488}
}

@INPROCEEDINGS{Kamaruddin:2016:MeasuringCustomerSatisfaction,  author={N. {Kamaruddin} and A. W. A. {Rahman} and A. N. R. {Shah}},  booktitle={2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M)},  title={Measuring Customer Satisfaction through Speech Using Valence-Arousal Approach},   year={2016},  volume={},  number={},  pages={298-303},}

@INPROCEEDINGS{Dong:2012:UnderstandHumanImplicitIntention,  author={ {Suh-Yeon Dong} and  {Soo-Young Lee}},  booktitle={The 2012 International Joint Conference on Neural Networks (IJCNN)},  title={Understanding human implicit intention based on frontal electroencephalography (EEG)},   year={2012},  volume={},  number={},  pages={1-5},}

@inbook{Salah:2018:Video-BasedEmotionRec,
author = {Salah, Albert and Kaya, Heysem and Gürpınar, Furkan},
year = {2018},
month = {12},
pages = {369–386},
title = {Video-Based Emotion Recognition in the Wild},
doi = {10.1016/B978-0-12-814601-9.00031-6}
}

@mastersthesis{Esser:2018:LandmarkDetection,
  author       = {Jan E{\ss}er}, 
  title        = {Verbesserung der Präzision der Landmark-Detektion bei Gesichtern mittels Machine Learning},
  school       = {RWTH Aachen University},
  year         = 2018,
  address      = {Germany}}

﻿@Article{Briesemeister:2011:DiscreteEmotion,
author={Briesemeister, Benny B.
and Kuchinke, Lars
and Jacobs, Arthur M.},
title={Discrete emotion norms for nouns: Berlin affective word list (DENN--BAWL)},
journal={Behavior Research Methods},
year={2011},
month={Mar},
day={17},
volume={43},
number={2},
pages={441},
issn={1554-3528},
doi={10.3758/s13428-011-0059-y},
url={https://doi.org/10.3758/s13428-011-0059-y}
}

@misc{Sharma:2018:RealTimeFacial,
  author = {Sharma, Gaurav},
  title = {Real Time Facial Expression Recognition},
  year = 2018,
  url = {https://medium.com/datadriveninvestor/real-time-facial-expression-recognition-f860dacfeb6a},
  urldate = {2020-04-28}
}

@article{Akcay:2020:SpeechEmotionRecognition(SER),
title = "Speech emotion recognition: Emotional models, databases, features, preprocessing methods, supporting modalities, and classifiers",
journal = "Speech Communication",
volume = "116",
pages = "56 - 76",
year = "2020",
issn = "0167-6393",
doi = "https://doi.org/10.1016/j.specom.2019.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S0167639319302262",
author = "Mehmet Berkehan Akçay and Kaya Oğuz",
keywords = "Speech emotion recognition, Survey, Speech features, Classification, Speech databases",
}

@book{Sigman:2017:TheSecretLifeOfTheMind,
author = {Sigman, Mariano},
year = {2017},
title = {The Secret Life of the Mind}
}

@misc{IBM:2020:TheImpactOfDigitization,
  author = {IBM},
  title = {The impact of digitization on the banking industry},
  year = {2018},
  url = {https://www.ibm.com/thought-leadership/institute-business-value/report/digitalbank},
  urldate = {2020-05-01}
}

@misc{Poddar:2016:MachineLearning,
 author = {Poddar, Divya},
 title = {Machine Learning: A Beginner’s Guide},
 year = {2016},
 url = {https://upxacademy.com/introduction-machine-learning/},
 note = {Last accessed on: 13.12.2017}
}

@article{Kossaifi:2017:AFEW-VADatabase,
title = "AFEW-VA database for valence and arousal estimation in-the-wild",
journal = "Image and Vision Computing",
volume = "65",
pages = "23 - 36",
year = "2017",
note = "Multimodal Sentiment Analysis and Mining in the Wild Image and Vision Computing",
issn = "0262-8856",
doi = "https://doi.org/10.1016/j.imavis.2017.02.001",
url = "http://www.sciencedirect.com/science/article/pii/S0262885617300379",
author = "Jean Kossaifi and Georgios Tzimiropoulos and Sinisa Todorovic and Maja Pantic",
}

@INPROCEEDINGS{Theagarajan:2018:DeepDriver,
    author={R. {Theagarajan} and B. {Bhanu} and A. {Cruz}},
    booktitle={2018 24th International Conference on Pattern Recognition (ICPR)},   title={DeepDriver: Automated System For measuring Valence and Arousal in Car Driver Videos},
    year={2018},
    volume={},
    number={},
    pages={2546-2551},}
    
@article{Handrich:2020:SimultaneousPredVA,
    title = "Simultaneous Prediction of Valence/Arousal and Emotions on AffectNet, Aff-Wild and AFEW-VA",
    journal = "Procedia Computer Science",
    volume = "170",
    pages = "634 - 641",
    year = "2020",
    note = "The 11th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 3rd International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops",
    issn = "1877-0509",
    doi = "https://doi.org/10.1016/j.procs.2020.03.134",
    url = "http://www.sciencedirect.com/science/article/pii/S1877050920305895",
    author = "Sebastian Handrich and Laslo Dinges and Ayoub Al-Hamadi and Philipp Werner and Zaher Al Aghbari",
    keywords = "Affective State, Valence, Arousal"
}

@INPROCEEDINGS{Cao:2018:VGGFace2, 
    author={Q. {Cao} and L. {Shen} and W. {Xie} and O. M. {Parkhi} and A. {Zisserman}},
    booktitle={2018 13th IEEE International Conference on Automatic Face   Gesture Recognition (FG 2018)},
    title={VGGFace2: A Dataset for Recognising Faces across Pose and Age},
    year={2018},
    volume={},
    number={},
    pages={67-74},}
    
@ARTICLE{Hossain:2019:AudioVisualER,  author={M. S. {Hossain} and G. {Muhammad}},  journal={IEEE Wireless Communications},   title={An Audio-Visual Emotion Recognition System Using Deep Learning Fusion for a Cognitive Wireless Framework},   year={2019},  volume={26},  number={3},  pages={62-68},}

@ARTICLE{Xing:2019:EEGAudioVisual,  author={B. {Xing} and H. {Zhang} and K. {Zhang} and L. {Zhang} and X. {Wu} and X. {Shi} and S. {Yu} and S. {Zhang}},  journal={IEEE Access},   title={Exploiting EEG Signals and Audiovisual Feature Fusion for Video Emotion Recognition},   year={2019},  volume={7},  number={},  pages={59844-59861},}
    
@INPROCEEDINGS{Hupont:2010:FacialEmotionsIn2DAffectiveSpace,
    author={I. {Hupont} and E. {Cerezo} and S. {Baldassarri}},
    booktitle={2010 IEEE International Conference on Systems, Man and Cybernetics},
    title={Sensing facial emotions in a continuous 2D affective space},
    year={2010},
    volume={},
    number={},
    pages={2045-2051},}
    
@inproceedings{Yan:2016:MultiClueFusion,
author = {Yan, Jingwei and Zheng, Wenming and Cui, Zhen and Tang, Chuangao and Zhang, Tong and Zong, Yuan and Sun, Ning},
title = {Multi-Clue Fusion for Emotion Recognition in the Wild},
year = {2016},
isbn = {9781450345569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993148.2997630},
doi = {10.1145/2993148.2997630},
booktitle = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
pages = {458–463},
numpages = {6},
keywords = {emotion recognition in the wild, convolutional neural network (CNN), AFEW, recurrent neural network (RNN), multi-clue},
location = {Tokyo, Japan},
series = {ICMI ’16}
}

@article{Zhang:2016:MTCCN,
   title={Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks},
   volume={23},
   ISSN={1558-2361},
   url={http://dx.doi.org/10.1109/LSP.2016.2603342},
   DOI={10.1109/lsp.2016.2603342},
   number={10},
   journal={IEEE Signal Processing Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
   year={2016},
   month={Oct},
   pages={1499–1503}
}

